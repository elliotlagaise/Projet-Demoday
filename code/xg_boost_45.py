# -*- coding: utf-8 -*-
"""xg_boost_45%

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UyQkyG33g-DJ97YEvukxRcVcDCFkfTye
"""
'''
!pip install --user xgboost

# CPU only

!pip install -q xgboost

# Install necessary dependencies
!apt-get install -y -qq libgpuarray-dev libnvrtc8.0 libnvtoolsext1

# Install GPU version of XGBoost
!pip install pyproject-toml
!pip install -q xgboost
!pip install category_encoders
'''
import seaborn as sns

import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import warnings

from sklearn.pipeline import Pipeline

from category_encoders.target_encoder import TargetEncoder

from xgboost import XGBClassifier

import pickle


df = pd.read_csv("result_dataset.csv")

df.head()

# Liste des colonnes à conserver
colonnes_a_garder = ['sexe', 'equipement', 'trajet', 'age', 'agg', 'atm', 'jour','grav']

# Suppression des colonnes non nécessaires
df = df[colonnes_a_garder]

# Affichage du DataFrame résultant
print(df)

# Importer les bibliothèques nécessaires
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# Remplacez 'target_column' par le nom de votre colonne cible
target_column_name = 'grav'

# Mappez les classes à partir de 0
class_mapping = {cls: idx for idx, cls in enumerate(np.unique(df[target_column_name]))}
df[target_column_name] = df[target_column_name].map(class_mapping)

# Diviser les données en fonctionnalités (X) et étiquettes (y)
X = df.drop(target_column_name, axis=1)
y = df[target_column_name]

# Diviser les données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Créer le modèle XGBoost multiclasse
model = XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y)), learning_rate=0.01,subsample=0.8, colsample_bytree=0.8,gamma=0.1)

# Entraîner le modèle
model.fit(X_train, y_train)

# Faire des prédictions sur l'ensemble de test
y_pred = model.predict(X_test)

# Évaluer les performances du modèle
accuracy = accuracy_score(y_test, y_pred)
print(f'Précision du modèle : {accuracy * 100:.2f}%')

# Afficher le rapport de classification
print('Rapport de classification :\n', classification_report(y_test, y_pred))

value_counts = df.value_counts("grav")

# Afficher les résultats
print(value_counts)

import pandas as pd
import numpy as np

# Exemple de DataFrame et de la colonne cible
data = {'grav': [1, 2, 3, 4]}
df = pd.DataFrame(data)

# Mapping initial
class_mapping_initial = {cls: idx for idx, cls in enumerate(np.unique(df['grav']))}

# Application du mapping
df['grav_mapped'] = df['grav'].map(class_mapping_initial)

# Mapping final
class_mapping_final = {cls: idx for idx, cls in enumerate(np.unique(df['grav_mapped']))}

# Vérifier si les valeurs ont été décrémentées de 1
decremented_by_1 = all(class_mapping_initial[cls] - 1 == class_mapping_final[cls] for cls in class_mapping_final if cls in class_mapping_initial)

print("Les valeurs ont-elles été décrémentées de 1 ?", decremented_by_1)

pickle.dump(model, open("xgb.pkl", "wb"))
import pickle

pickle.dump(model, open("xgb.pkl";"wb"))

loaded_model=pickle.load(open("xgb.pkl","rb"))